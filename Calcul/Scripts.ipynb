{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id      screen_name                name           created_at  \\\n",
      "0  1,72517E+18       gptournier  Guillaume Tournier  2023-11-16 15:13:18   \n",
      "1  1,72868E+18       jouanetwan      Jouan Etwan üíöüíõ  2023-11-26 07:34:34   \n",
      "2  1,73784E+18  vince_thouvenin           thouvenin  2023-12-21 14:27:08   \n",
      "3  1,74049E+18   BiduleAnatheme     Anath√®me Bidule  2023-12-28 21:32:58   \n",
      "4  1,74068E+18  vince_thouvenin           thouvenin  2023-12-29 10:08:10   \n",
      "\n",
      "                                           full_text  hour  text_length  \\\n",
      "0  ENGIEpartFR n6 mois dattente et tjs aucune reÃÅ...    15          282   \n",
      "1  Bonjour ENGIEpartSAV , lappli monpilotageelec ...     7          155   \n",
      "2  ENGIEpartFR mon syndic de coproprieÃÅteÃÅ sergic...    14          219   \n",
      "3  ENGIEpartSAV vous envisagez de vous occuper de...    21          267   \n",
      "4  ENGIEpartSAV retour de votre technicien vous n...    10          240   \n",
      "\n",
      "   contains_engie  \n",
      "0            True  \n",
      "1            True  \n",
      "2            True  \n",
      "3            True  \n",
      "4            True  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/data_cleaned.csv', sep=None, engine='python', encoding='utf-8-sig')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tweets par jour: day\n",
      "2023-11-16    1\n",
      "2023-11-26    1\n",
      "2023-12-21    1\n",
      "2023-12-28    1\n",
      "2023-12-29    4\n",
      "             ..\n",
      "2025-02-24    9\n",
      "2025-02-25    3\n",
      "2025-02-26    3\n",
      "2025-03-03    5\n",
      "2025-03-04    1\n",
      "Length: 292, dtype: int64\n",
      "Nombre de tweets par semaine: week\n",
      "2023-11-13/2023-11-19     1\n",
      "2023-11-20/2023-11-26     1\n",
      "2023-12-18/2023-12-24     1\n",
      "2023-12-25/2023-12-31     6\n",
      "2024-01-01/2024-01-07    12\n",
      "                         ..\n",
      "2025-02-03/2025-02-09     3\n",
      "2025-02-10/2025-02-16     8\n",
      "2025-02-17/2025-02-23    11\n",
      "2025-02-24/2025-03-02    15\n",
      "2025-03-03/2025-03-09     6\n",
      "Freq: W-SUN, Length: 66, dtype: int64\n",
      "Nombre de tweets par mois: month\n",
      "2023-11     2\n",
      "2023-12     7\n",
      "2024-01    60\n",
      "2024-02    57\n",
      "2024-03    55\n",
      "2024-04    41\n",
      "2024-05    41\n",
      "2024-06    22\n",
      "2024-07    28\n",
      "2024-08    28\n",
      "2024-09    24\n",
      "2024-10    40\n",
      "2024-11    43\n",
      "2024-12    44\n",
      "2025-01    41\n",
      "2025-02    37\n",
      "2025-03     6\n",
      "Freq: M, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convertir 'created_at' en format datetime\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\")\n",
    "\n",
    "# Ajouter des colonnes pour le jour, la semaine et le mois\n",
    "df[\"day\"] = df[\"created_at\"].dt.date\n",
    "df[\"week\"] = df[\"created_at\"].dt.to_period('W')\n",
    "df[\"month\"] = df[\"created_at\"].dt.to_period('M')\n",
    "\n",
    "# Calcul du nombre de tweets par jour, semaine et mois\n",
    "tweets_par_jour = df.groupby(\"day\").size()\n",
    "tweets_par_semaine = df.groupby(\"week\").size()\n",
    "tweets_par_mois = df.groupby(\"month\").size()\n",
    "\n",
    "print(\"Nombre de tweets par jour:\", tweets_par_jour)\n",
    "print(\"Nombre de tweets par semaine:\", tweets_par_semaine)\n",
    "print(\"Nombre de tweets par mois:\", tweets_par_mois)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentions de comptes Engie par jour: day\n",
      "2023-11-16    1\n",
      "2023-11-26    1\n",
      "2023-12-21    1\n",
      "2023-12-28    1\n",
      "2023-12-29    4\n",
      "             ..\n",
      "2025-02-24    9\n",
      "2025-02-25    5\n",
      "2025-02-26    3\n",
      "2025-03-03    6\n",
      "2025-03-04    2\n",
      "Name: mentions_engie, Length: 292, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df[\"mentions_engie\"] = df[\"full_text\"].apply(lambda x: len(re.findall(r'ENGIE\\w+', x)))\n",
    "\n",
    "mentions_par_jour = df.groupby(\"day\")[\"mentions_engie\"].sum()\n",
    "\n",
    "print(\"Mentions de comptes Engie par jour:\", mentions_par_jour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets critiques par jour: day\n",
      "2023-11-16    0\n",
      "2023-11-26    0\n",
      "2023-12-21    1\n",
      "2023-12-28    0\n",
      "2023-12-29    0\n",
      "             ..\n",
      "2025-02-24    0\n",
      "2025-02-25    0\n",
      "2025-02-26    0\n",
      "2025-03-03    0\n",
      "2025-03-04    0\n",
      "Name: tweet_critique, Length: 292, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mots_cles = [\"d√©lai\", \"panne\", \"urgence\", \"scandale\"]\n",
    "\n",
    "def contient_mots_cles(tweet):\n",
    "    return any(mot in tweet.lower() for mot in mots_cles)\n",
    "\n",
    "df[\"tweet_critique\"] = df[\"full_text\"].apply(contient_mots_cles)\n",
    "\n",
    "tweets_critique_par_jour = df.groupby(\"day\")[\"tweet_critique\"].sum()\n",
    "\n",
    "print(\"Tweets critiques par jour:\", tweets_critique_par_jour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats = pd.DataFrame({\n",
    "    \"tweets_par_jour\": tweets_par_jour,\n",
    "    \"tweets_par_semaine\": tweets_par_semaine.reindex(tweets_par_jour.index, fill_value=0),\n",
    "    \"tweets_par_mois\": tweets_par_mois.reindex(tweets_par_jour.index, fill_value=0),\n",
    "    \"mentions_engie_par_jour\": mentions_par_jour,\n",
    "    \"tweets_critique_par_jour\": tweets_critique_par_jour\n",
    "})\n",
    "\n",
    "resultats.to_csv('../Data/resultats_analyse_tweets.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positifs: 26\n",
      "N√©gatifs: 550\n",
      "Neutres: 0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s‚Äôest bloqu√© lors de l‚Äôex√©cution du code dans une cellule active ou une cellule pr√©c√©dente. \n",
      "\u001b[1;31mVeuillez v√©rifier le code dans la ou les cellules pour identifier une cause possible de l‚Äô√©chec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d‚Äôinformations. \n",
      "\u001b[1;31mPour plus d‚Äôinformations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Charger le pipeline d'analyse de sentiment\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Appliquer l'analyse de sentiment √† chaque tweet\n",
    "df['sentiment'] = df['full_text'].apply(lambda x: sentiment_analyzer(x)[0]['label'])\n",
    "\n",
    "# Classer les tweets en cat√©gories Positif, N√©gatif, Neutre\n",
    "df['sentiment_class'] = df['sentiment'].apply(lambda x: 'Positif' if x == 'POSITIVE' else ('N√©gatif' if x == 'NEGATIVE' else 'Neutre'))\n",
    "\n",
    "df.to_csv('../Data/data_cleaned_with_analysis.csv', index=False)\n",
    "\n",
    "# Classer les tweets en cat√©gories Positif, N√©gatif, Neutre\n",
    "positive_tweets = df[df['sentiment'] == 'POSITIVE']\n",
    "negative_tweets = df[df['sentiment'] == 'NEGATIVE']\n",
    "neutral_tweets = df[df['sentiment'] == 'NEUTRAL']\n",
    "\n",
    "# Affichage de la r√©partition des sentiments\n",
    "print(f\"Positifs: {len(positive_tweets)}\")\n",
    "print(f\"N√©gatifs: {len(negative_tweets)}\")\n",
    "print(f\"Neutres: {len(neutral_tweets)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
